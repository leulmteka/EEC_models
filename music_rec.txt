# Explanation of the Spotify Recommender System

When you run this Spotify recommender system, it combines several machine learning techniques to create personalized music recommendations. Here's a step-by-step explanation of what happens:

## 1. Data Loading and Preparation

```python
dataset_path = download_dataset()
df = load_data(dataset_path)
df, display_df, features = preprocess_data(df)
```

- **Dataset Download**: The system first tries to download the Spotify dataset (30,000 songs) from Kaggle
- **Data Loading**: It loads the CSV file containing song information
- **Preprocessing**: 
  - Handles missing values
  - Extracts relevant audio features (acousticness, danceability, energy, etc.)
  - Normalizes these features using StandardScaler to put them on the same scale
  - Creates a clean version of the dataframe for display purposes

## 2. Initial Song Selection

```python
initial_songs = select_initial_songs(df, n=25)
```

- Selects 25 diverse songs for you to rate
- Ensures variety by picking songs from different genres and popularity levels
- This diversity helps the system learn your preferences across different types of music

## 3. User Preference Collection

```python
liked_ids, disliked_ids, neutral_ids = get_user_ratings(display_df, initial_songs)
```

- Presents each selected song with its details
- You rate each song as "like", "dislike", or "neutral"
- These ratings form the basis for understanding your music taste

## 4. Building Recommendation Models

The system trains four different recommendation models:

### a. Content-Based Recommender

```python
content_model = ContentBasedRecommender(df, features).fit()
```

- **What it does**: Recommends songs with similar audio features to ones you liked
- **How it works**:
  - Creates a similarity matrix between all songs based on their audio features
  - When recommending, it finds songs most similar to your liked songs
  - It also avoids songs similar to your disliked songs
  - Uses cosine similarity to measure how similar two songs are based on their features

### b. Clustering Recommender

```python
cluster_model = ClusteringRecommender(df, features).fit()
```

- **What it does**: Groups similar songs into clusters and recommends from your preferred clusters
- **How it works**:
  - Uses K-means clustering to group songs into 10 clusters based on audio features
  - Identifies which clusters contain songs you liked
  - Recommends other songs from those same clusters
  - Avoids clusters containing songs you disliked

### c. Matrix Factorization with ALS (Alternating Least Squares)

```python
als_model = ALSRecommender(df, features).fit()
```

- **What it does**: Discovers latent factors that explain your preferences
- **How it works**:
  - Creates a user-item matrix where rows represent users and columns represent songs
  - Decomposes this matrix into two lower-dimensional matrices (user factors and item factors)
  - These factors represent hidden characteristics that determine your music taste
  - Uses the implicit library's ALS implementation which is designed for implicit feedback
  - Updates the model with your likes/dislikes and recommends songs with high predicted ratings

### d. Deep Learning Recommender

```python
deep_model = DeepRecommender(df, features).fit()
```

- **What it does**: Uses neural networks to learn complex patterns in your preferences
- **How it works**:
  - Creates a simple neural network with two hidden layers
  - Takes song features as input and predicts your preference score
  - Trains on your liked songs (target=1) and disliked songs (target=0)
  - Uses this trained model to predict scores for all unrated songs
  - Recommends songs with the highest predicted scores

## 5. Ensemble Recommendation

```python
ensemble = EnsembleRecommender([content_model, cluster_model, als_model, deep_model], 
                              weights=[0.3, 0.2, 0.3, 0.2])
recommendations = ensemble.recommend(liked_ids, disliked_ids, n=15)
```

- **What it does**: Combines recommendations from all four models for better results
- **How it works**:
  - Gets recommendations from each individual model
  - Assigns weights to each model (content and ALS models have higher weight)
  - Scores each recommended song based on:
    - Which models recommended it
    - The weight of those models
    - The position in each model's recommendation list
  - Returns the top 15 songs with the highest combined scores

## 6. Continuous Learning Loop

```python
# Inside the main loop
if choice == '1':
    # Rate more songs and update recommendations
elif choice == '2':
    # Get more recommendations with current preferences
```

- The system continues to learn from your feedback
- You can rate more songs to refine your profile
- Each time you provide new ratings, all models update their understanding of your preferences
- The recommendations continuously improve as you interact with the system

## Technical ML Concepts Used

1. **Feature Normalization**: Scales all audio features to have mean=0 and standard deviation=1
2. **Cosine Similarity**: Measures similarity between songs based on the angle between their feature vectors
3. **K-means Clustering**: Unsupervised learning algorithm that groups similar songs
4. **Matrix Factorization**: Collaborative filtering technique that finds latent factors
5. **Neural Networks**: Deep learning approach that learns complex patterns
6. **Ensemble Methods**: Combines multiple models for better performance
7. **Sparse Matrices**: Efficiently represents user-item interactions where most values are zero
8. **Implicit Feedback**: Works with binary interactions (like/dislike) rather than explicit ratings

The system is designed to be robust, with fallback mechanisms if any model fails, and to handle various edge cases that might occur during the recommendation process.


RESULTS:

=== ENERGY CONSUMPTION REPORT ===
Total Energy Consumption: 4.167497 kWh
Estimated CO2 Emissions: 4.940381 kg CO2eq
(Note: GPU energy was estimated as direct measurement failed)

This is equivalent to:
- Charging a smartphone 328.1 times
- Keeping a 10W LED light bulb on for 416.7 hours
- Driving a car for 12.35 miles

Energy breakdown by component:
- Initial Recommendation: 0.825060 kWh (19.8%)
- Recommendation Round 1: 0.820631 kWh (19.7%)
- Recommendation Round 2: 0.795688 kWh (19.1%)
- Clustering Model: 0.738241 kWh (17.7%)
- Matrix Factorization Model: 0.512463 kWh (12.3%)
- Pure Collaborative Filtering Model: 0.326044 kWh (7.8%)
- Content-based Model: 0.135422 kWh (3.2%)
- Deep Learning Model: 0.013948 kWh (0.3%)


=== PERFORMANCE REPORT ===
Content-Based Model Training: 17.06 seconds
Clustering Model Training: 79.50 seconds
Pure Collaborative Filtering Training: 30.44 seconds
Matrix Factorization Training: 47.87 seconds
Deep Learning Model Training: 0.87 seconds
Total Training Time: 175.75 seconds

Recommendation Generation Times (Initial):
- Full Ensemble: 77.68 seconds
- Pruned ML: 0.79 seconds
- Genre-Based: 0.06 seconds
- Popularity-Based: 0.01 seconds

=== ENERGY EFFICIENCY COMPARISON ===
Ranking from most to least energy efficient:
1. Popularity-Based Random: 0.01 seconds
2. Genre-Based Random: 0.06 seconds
3. Pruned ML: 0.79 seconds
4. Full Ensemble ML: 77.68 seconds

Relative Efficiency (compared to fastest method):
- Popularity-Based Random: 1.00x slower than fastest
- Genre-Based Random: 8.15x slower than fastest
- Pruned ML: 113.44x slower than fastest
- Full Ensemble ML: 11167.22x slower than fastest

=== ENERGY CONSUMPTION REPORT ===
Total Energy Consumption: 4.642943 kWh
Estimated CO2 Emissions: 5.853699 kg CO2eq
(Note: GPU energy was estimated as direct measurement failed)

This is equivalent to:
- Charging a smartphone 365.6 times
- Keeping a 10W LED light bulb on for 464.3 hours
- Driving a car for 14.63 miles

Energy breakdown by component:
- Full Ensemble Recommendations: 1.331328 kWh (28.7%)
- Full Ensemble Round 1: 0.952255 kWh (20.5%)
- Clustering Model: 0.775798 kWh (16.7%)
- Full Ensemble Round 2: 0.588040 kWh (12.7%)
- Matrix Factorization Model: 0.503723 kWh (10.8%)
- Pure Collaborative Filtering Model: 0.320272 kWh (6.9%)
- Content-based Model: 0.138620 kWh (3.0%)
- Deep Learning Model: 0.012976 kWh (0.3%)
- Pruned ML Recommendations: 0.006585 kWh (0.1%)
- Pruned ML Round 1: 0.006187 kWh (0.1%)
- Pruned ML Round 2: 0.005973 kWh (0.1%)
- Genre-Based Round 2: 0.000429 kWh (0.0%)
- Genre-Based Round 1: 0.000326 kWh (0.0%)
- Genre-Based Recommendations: 0.000263 kWh (0.0%)
- Popularity-Based Recommendations: 0.000060 kWh (0.0%)
- Popularity-Based Round 1: 0.000053 kWh (0.0%)
- Popularity-Based Round 2: 0.000053 kWh (0.0%)